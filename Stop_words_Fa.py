import nltk
from nltk.tokenize import word_tokenize
from bs4 import BeautifulSoup
import re
import os

nltk.download('punkt')

# Define the directory where the output file is located
output_directory = 'outputs'

# Define the input file path (assuming it's in the 'outputs' directory)
input_file_path = os.path.join(output_directory, 'cleaned_text.txt')  # Assuming English text

with open(input_file_path, "r", encoding="utf-8") as file:
    html_text = file.read()

# Remove tags and convert to plain text
text = BeautifulSoup(html_text, 'html.parser').get_text()

# Tokenize the text into words
words = word_tokenize(text)

# Define Persian stopwords
persian_stop_words = set([
  "و", "در", "به", "از", "که", "این", "را", "با", "برای", "آن", "یک", "خود",
    "تا", "کرد", "بر", "هم", "نیز", "گفت", "می‌شود", "وی", "شد", "دارد", "ما",
    "اما", "یا", "شده", "باید", "هر", "آنها", "بود", "او", "دیگر", "دو", "مورد",
    "می‌کند", "شود", "کند", "وجود", "بین", "پیش", "شده_است", "پس", "نظر",
    "اگر", "همه", "یکی", "حال", "هستند", "من", "کنند", "نیست", "باشد", "چه",
    "بی", "می", "بخش", "می‌کنند", "همین", "افزود", "هایی", "دارند", "راه",
    "همچنین", "روی", "داد", "بیشتر", "بسیار", "سه", "داشت", "چند", "سوی",
    "تنها", "هیچ", "میان", "اینکه", "شدن", "بعد", "جدید", "ولی", "حتی", "کردن",
    "برخی", "کردند", "می‌دهد", "اول", "نه", "کرده_است", "نسبت", "بیش",
    "شما", "چنین", "طور", "افراد", "تمام", "درباره", "بار", "بسیاری", "می‌تواند",
    "کرده", "چون", "ندارد", "دوم", "بزرگ", "طی", "حدود", "همان", "بدون",
    "البته", "آنان", "می‌گوید", "دیگری", "خواهد_شد", "کنیم", "قابل", "یعنی",
    "رشد", "می‌توان", "وارد", "کل", "ویژه", "قبل", "براساس", "نیاز", "گذاری",
    "هنوز", "لازم", "سازی", "بوده_است", "چرا", "می‌شوند", "وقتی", "گرفت",
    "کم", "جای", "حالی", "تغییر", "پیدا", "اکنون", "تحت", "باعث", "مدت",
    "فقط", "زیادی", "تعداد", "آیا", "بیان", "رو", "شدند", "عدم", "کرده_اند",
    "بودن", "نوع", "بلکه", "جاری", "دهد", "برابر", "مهم", "بوده", "اخیر",
    "مربوط", "امر", "زیر", "گیری", "شاید", "خصوص", "آقای", "اثر", "کننده",
    "بودند", "فکر", "کنار", "اولین", "سوم", "سایر", "کنید", "ضمن", "مانند",
    "باز", "می‌گیرد", "ممکن", "حل", "دارای", "پی", "مثل", "می‌رسد", "اجرا",
    "دور", "منظور", "کسی", "موجب", "طول", "امکان", "آنچه", "تعیین", "گفته",
    "شوند", "جمع", "خیلی", "علاوه", "گونه", "تاکنون", "رسید", "ساله", "گرفته",
    "شده_اند", "علت", "چهار", "داشته_باشد", "خواهد_بود", "طرف", "تهیه", "تبدیل",
    "مناسب", "زیرا", "مشخص", "می‌توانند", "نزدیک", "جریان", "روند", "بنابراین",
    "می‌دهند", "یافت", "نخستین", "بالا", "پنج", "ریزی", "عالی", "چیزی",
    "نخست", "بیشتری", "ترتیب", "شده_بود", "خاص", "خوبی", "خوب", "شروع", "فرد",
    "کامل", "غیر", "می‌رود", "دهند", "آخرین", "دادن", "جدی", "بهترین", "شامل",
    "گیرد", "بخشی", "باشند", "تمامی", "بهتر", "داده_است", "حد", "نبود",
    "کسانی", "می‌کرد", "داریم", "علیه", "می‌باشد", "دانست", "ناشی", "داشتن",
    "دهه", "می‌شد", "ایشان", "آنجا", "گرفته_است", "دچار", "می‌آید", "لحاظ",
    "آنکه", "داده", "بعضی", "هستیم", "اند", "برداری", "نباید", "می‌کنیم",
    "نشست", "سهم", "همیشه", "آمد", "اش", "وگو", "می‌کنم", "حداقل", "طبق", "جا",
    "خواهد_کرد", "نوعی", "چگونه", "رفت", "هنگام", "فوق", "روش", "ندارند",
    "سعی", "بندی", "شمار", "کلی", "کافی", "مواجه", "همچنان", "زیاد", "سمت",
    "کوچک", "داشته_است", "چیز", "پشت", "آورد", "حالا", "روبه", "سال‌های",
    "دادند", "می‌کردند", "عهده", "نیمه", "جایی", "دیگران", "سی", "بروز",
    "یکدیگر", "آمده_است", "جز", "کنم", "سپس", "کنندگان", "خودش", "همواره",
    "یافته", "شان", "صرف", "نمی‌شود", "رسیدن", "چهارم", "یابد", "متر", "ساز",
    "داشته", "کرده_بود", "باره", "نحوه", "کردم", "تو", "شخصی", "داشته_باشند",
    "محسوب", "پخش", "کمی", "متفاوت", "سراسر", "کاملا", "داشتن", "نظیر",
    "آمده", "گروهی", "فردی", "ع"
])

# Remove stopwords from tokens
filtered_tokens = [word for word in words if word.lower() not in persian_stop_words]

# Join the cleaned words into a string
filtered_text = ' '.join(filtered_tokens)

# Get the directory of the input file
input_directory = os.path.dirname(os.path.abspath('cleaned_text.txt'))


# Define the output directory path
output_directory = 'outputs'

# Ensure the 'outputs' directory exists
os.makedirs(output_directory, exist_ok=True)

# Define the output file path
output_file_path = os.path.join(output_directory, 'filtered.txt')

# Save the cleaned text to the output file
with open(output_file_path, 'w', encoding='utf-8') as output_file:
    output_file.write(filtered_text)

print("Cleaned text has been saved to 'filtered.txt' in the 'outputs' directory.")

